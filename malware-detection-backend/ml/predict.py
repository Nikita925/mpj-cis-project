import sys
import os
import pickle
import numpy as np
import math

# Paths to the pre-trained models
model_paths = {
    "logistic_regression": 'ml/logistic_regression_model.pkl',
    "decision_tree": 'ml/decision_tree_model.pkl',
    "random_forest": 'ml/random_forest_model.pkl',
    "knn": 'ml/knn_model.pkl',
    "svm": 'ml/svm_model.pkl'
}

# Extracts features from the file for prediction
def extract_features(file_path):
    file_size = os.path.getsize(file_path)
    specials = count_special_characters(file_path)
    entropy = calculate_entropy(file_path)
    suspicious_strings_count = count_suspicious_strings(file_path)
    file_name = os.path.basename(file_path)
    extension = extract_extension(file_name)
    
    return np.array([file_size, specials, entropy, suspicious_strings_count, len(file_name), len(extension)])

# Counts the number of non-alphanumeric (special) characters in the file
def count_special_characters(file_path):
    with open(file_path, 'rb') as f:
        content = f.read()
    specials = sum(not (65 <= b <= 90 or 97 <= b <= 122 or 48 <= b <= 57) for b in content)
    return specials

# Calculates the entropy of the file's content (higher entropy can mean obfuscation)
def calculate_entropy(file_path):
    with open(file_path, 'rb') as f:
        content = f.read()
    
    byte_frequencies = [content.count(i) / len(content) for i in range(256)]
    entropy = -sum([f * math.log2(f) for f in byte_frequencies if f > 0])
    return entropy

# Extracts the file extension
def extract_extension(file_name):
    return file_name.split('.')[-1] if '.' in file_name else 'unknown'

# Counts the occurrence of suspicious keywords inside the file
def count_suspicious_strings(file_path):
    with open(file_path, 'rb') as f:
        content = f.read().decode(errors='ignore')
    suspicious_strings = ['cmd', 'powershell', 'netstat', 'ftp', 'wget', 'eval']
    count = sum([content.lower().count(s) for s in suspicious_strings])
    return count

def main():
    file_path = sys.argv[1]  # Get the file path from command-line arguments
    features = extract_features(file_path)  # Extract features from the file

    model_predictions = {}

    # Predict the label using each model
    for name, path in model_paths.items():
        with open(path, 'rb') as f:
            model = pickle.load(f)
        
        prediction = model.predict([features])
        label = "malware" if prediction[0] == 1 else "benign"
        model_predictions[name] = label

    # Majority voting: count how many models voted "malware" vs "benign"
    malware_votes = list(model_predictions.values()).count("malware")
    benign_votes = list(model_predictions.values()).count("benign")

    # Final result based on the majority vote
    final_result = "malware" if malware_votes > benign_votes else "benign"

    # Output the final decision and individual model votes
    print(f"{final_result}")
    print(f"{model_predictions}")

if __name__ == "__main__":
    main()
